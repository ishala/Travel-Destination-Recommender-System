{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step By Step Pengerjaan (Deadline 3 September 2024)\n",
    "- Cocokin data byPlaceData.csv dengan scrapetable_wisata.xlsx\n",
    "- Mengubah konten menjadi bahasa indonesia, dengan mengambil data dari byPlaceData.csv\n",
    "- Data yang tidak ada di scrapetable_wisata.xlsx langsung di drop saja di byPlaceData.csv (mengurangi storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# dataLamaPath = 'data/new-fix-data.csv'\n",
    "dataBaruPath = 'data/scrapetable_wisata.xlsx'\n",
    "dataByPlace = 'data/byPlaceData.csv'\n",
    "dataFiltered = 'data/filtered_byPlaceData.csv'\n",
    "\n",
    "# dfOld = pd.read_csv(dataLamaPath)\n",
    "dfNew = pd.read_excel(dataBaruPath)\n",
    "dfByPlace = pd.read_csv(dataByPlace)\n",
    "dfFiltered = pd.read_csv(dataFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfByPlace.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cek Info DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ByPlace\n",
    "print('By Place')\n",
    "print(dfByPlace.info())\n",
    "\n",
    "print()\n",
    "\n",
    "# new\n",
    "print('New')\n",
    "print(dfNew.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cek Nilai Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ByPlace\n",
    "print('By Place')\n",
    "print(dfByPlace.isna().sum())\n",
    "\n",
    "print()\n",
    "\n",
    "# new\n",
    "print('New')\n",
    "print(dfNew.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cek Nilai Duplikat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ByPlace\n",
    "print('By Place')\n",
    "print(dfByPlace.duplicated().sum())\n",
    "\n",
    "print()\n",
    "\n",
    "# new\n",
    "print('New')\n",
    "print(dfNew.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pemilihan Kolom Data Bu Melany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfNew.latitude.sample(1))\n",
    "print(dfNew.longitude.sample(1))\n",
    "\n",
    "print(dfByPlace.coordinates.sample(1))\n",
    "print(dfByPlace.address.sample(1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfNew.timezone.unique())\n",
    "print(dfNew.review_count.sample(1))\n",
    "print(dfNew.place_id.sample(1))\n",
    "print(dfNew.city.unique())\n",
    "print(dfNew['validasi di jogja dan tetangga'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1: Menghapus kolom dengan banyak missing values\n",
    "dfByPlace_cleaned = dfByPlace.drop(columns=['is_rating_updated', 'is_reviews_updated'])\n",
    "\n",
    "# Dataset 2: Menghapus kolom dengan banyak missing values dan mengisi missing values lainnya\n",
    "dfNew_cleaned = dfNew.drop(columns=['price_level'])\n",
    "\n",
    "# Mengisi missing values pada kolom numerik dengan median\n",
    "dfNew_cleaned['phone_number'].fillna('Unknown', inplace=True)\n",
    "# dfNew_cleaned['review_count'].fillna(dfNew_cleaned['review_count'].median(), inplace=True) (Dipertimbangkan)\n",
    "dfNew_cleaned['rating'].fillna(dfNew_cleaned['rating'].median(), inplace=True)\n",
    "\n",
    "# Mengisi missing values pada kolom string dengan 'Unknown'\n",
    "dfNew_cleaned['website'].fillna('Unknown', inplace=True)\n",
    "columns_to_fill = ['Friday', 'Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'state']\n",
    "for column in columns_to_fill:\n",
    "    dfNew_cleaned[column].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Memeriksa kembali missing values setelah pembersihan\n",
    "missing_values_dfByPlace_cleaned = dfByPlace_cleaned.isnull().sum()\n",
    "missing_values_dfNew_cleaned = dfNew_cleaned.isnull().sum()\n",
    "\n",
    "missing_values_dfByPlace_cleaned, missing_values_dfNew_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menggabungkan Data dan Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggabungkan data dari kedua dataset berdasarkan kolom address\n",
    "# Menentukan keyword untuk filtering\n",
    "keywords = [\"Jawa Tengah\", \"Central Java\", \"Yogyakarta\", \"Special Region of Yogyakarta\"]\n",
    "\n",
    "# Filter Dataset 1\n",
    "filtered_dfByPlace = dfByPlace_cleaned[dfByPlace_cleaned['address'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "\n",
    "# Filter Dataset 2\n",
    "filtered_dfNew = dfNew_cleaned[dfNew_cleaned['full_address'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "\n",
    "# Menggabungkan kedua dataset yang telah difilter\n",
    "combined_dataset = pd.concat([filtered_dfByPlace, filtered_dfNew], ignore_index=True)\n",
    "\n",
    "# Menampilkan jumlah baris dan kolom dari dataset yang digabungkan\n",
    "combined_shape = combined_dataset.shape\n",
    "combined_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the names in both datasets to lowercase for better matching\n",
    "# dfByPlace['name'] = dfByPlace['name'].str.lower()\n",
    "# dfNew['name'] = dfNew['name']\n",
    "\n",
    "# Filter out rows in byPlaceData that do not have a matching name in scrapetable_wisata\n",
    "filtered_data = dfByPlace[(dfByPlace['name'].str.lower()).isin((dfNew['name']).str.lower())]\n",
    "\n",
    "# Now filter based on the address containing 'Jawa Tengah', 'Central Java', or 'Yogyakarta'\n",
    "filtered_data = filtered_data[\n",
    "    filtered_data['address'].str.contains('Jawa Tengah|Central Java|Yogyakarta', case=False)\n",
    "]\n",
    "\n",
    "# Display the first few rows of the filtered data to verify\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered data to a new CSV file\n",
    "filtered_data_path = 'data/filtered_byPlaceData.csv'\n",
    "filtered_data.to_csv(filtered_data_path, index=False)\n",
    "\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambil Data dari DF Baru\n",
    "Pengambilan data yang mungkin masih merupakan wisata dari data baru, tapi tidak ada di data utama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickedData = dfNew[~dfNew['name'].str.lower().isin(filtered_data['name'].str.lower())]\n",
    "\n",
    "filteredCols = filtered_data.columns\n",
    "unpickedCols = unpickedData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data Fix\n",
    "\n",
    "Data yang disini sudah hasil pengambilan dari data baru, yang tidak ada di data lama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf = pd.read_csv('data/fixed_data.csv')\n",
    "fixedDf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cek Nilai Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memindahkan Nilai dari Kolom ke Kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi drop kolom\n",
    "def dropCol(df, lsCol):\n",
    "    col1 = lsCol[0]\n",
    "    col2 = lsCol[1]\n",
    "    \n",
    "    if col1 == 'latitude' and col2 == 'longitude':\n",
    "        df.drop(columns=[col1, col2], inplace=True)\n",
    "    else:\n",
    "        df.drop(columns=[col2], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Fungsi Pemindah Nilai\n",
    "def moveValues(col1, col2, df):\n",
    "    # Kondisi coordinates\n",
    "    if col1 == 'latitude' and col2 == 'longitude':\n",
    "        # Menggabungkan koordinat dan menyimpannya pada kolom 'coordinates'\n",
    "        df['coordinates'] = df.apply(lambda row: f\"{row[col1]},{row[col2]}\" if pd.isna(row['coordinates']) else row['coordinates'], axis=1)\n",
    "        \n",
    "        # Menghapus kolom latitude dan longitude\n",
    "        df = dropCol(df, [col1, col2])\n",
    "    else:\n",
    "        # Mengecek baris dengan NaN pada col1\n",
    "        mask_nullCol1 = df[col1].isna()\n",
    "        \n",
    "        if mask_nullCol1.any():\n",
    "            df.loc[mask_nullCol1, col1] = df.loc[mask_nullCol1, col2]\n",
    "        else:\n",
    "            print('Data tidak ada isinya')\n",
    "        \n",
    "        # Menghapus kolom col1 dan col2\n",
    "        df = dropCol(df, [col1, col2])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kolom Address dan Full Address\n",
    "fixedDf = moveValues('address', 'full_address', fixedDf)\n",
    "# Kolom latitude dan longitude\n",
    "fixedDf = moveValues('latitude', 'longitude', fixedDf)\n",
    "# Kolom latitude dan longitude\n",
    "fixedDf = moveValues('reviews', 'review_count', fixedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hapus Kolom Sisa yang Tidak Digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delCols = ['is_rating_updated', 'is_reviews_updated', 'website', \n",
    "           'business_id', 'phone_number', 'Unnamed: 0.1', 'Unnamed: 0', 'price_level']\n",
    "\n",
    "fixedDf.drop(columns=delCols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menangani Nilai Null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. timezone (Faishal)\n",
    "   \n",
    "Diisi dengan nilai unique, yaitu Asia/Jakarta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nilai unique: ', fixedDf.timezone.unique())\n",
    "fixedDf.timezone.fillna('Asia/Jakarta', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. types (Akhdan)\n",
    "\n",
    "Diisi sesuai dengan bidangnya, dilihat dari nilai unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nilai unique: ', fixedDf.types.unique())\n",
    "# fixedDf.timezone.fillna('Asia/Jakarta', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. city (Faishal)\n",
    "   \n",
    "Diisi dengan menggunakan regex dari full address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. workday_timing dan closed_on (Faishal)\n",
    "\n",
    "Ambil dari yang hari-hari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. reviews dan rating (Akhdan)\n",
    "   \n",
    "Manual aja ambil dari maps, kalau memungkinkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. reviewer_name, rating_review, dan review_text (Akhdan)\n",
    "\n",
    "ambil dari maps juga, masing2 data 1 ajaa kalo yang null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. validasi di jogja dan tetangga (Akhdan)\n",
    "\n",
    "Langsung isi pake nilai terbanyak aja, keknya udah di jogja dan sekitarnya semua ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf['validasi di jogja dan tetangga'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengatur gaya visualisasi\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1. Memeriksa missing values\n",
    "missing_values_dfByPlace = dfByPlace.isnull().sum()\n",
    "missing_values_dfNew = dfNew.isnull().sum()\n",
    "\n",
    "# 2. Visualisasi distribusi rating\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Dataset 1\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(dfByPlace['rating'], bins=20, kde=True)\n",
    "plt.title('Distribusi Rating - Dataset 1')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frekuensi')\n",
    "\n",
    "# Dataset 2\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(dfNew['rating'], bins=20, kde=True)\n",
    "plt.title('Distribusi Rating - Dataset 2')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frekuensi')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Visualisasi distribusi jumlah review\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Dataset 1\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(dfByPlace['reviews'], bins=20, kde=True)\n",
    "plt.title('Distribusi Jumlah Review - Dataset 1')\n",
    "plt.xlabel('Jumlah Review')\n",
    "plt.ylabel('Frekuensi')\n",
    "\n",
    "# Dataset 2\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(dfNew['review_count'], bins=20, kde=True)\n",
    "plt.title('Distribusi Jumlah Review - Dataset 2')\n",
    "plt.xlabel('Jumlah Review')\n",
    "plt.ylabel('Frekuensi')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "missing_values_dfByPlace, missing_values_dfNew"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
