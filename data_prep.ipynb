{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step By Step Pengerjaan (Deadline 3 September 2024)\n",
    "- Cocokin data byPlaceData.csv dengan scrapetable_wisata.xlsx\n",
    "- Mengubah konten menjadi bahasa indonesia, dengan mengambil data dari byPlaceData.csv\n",
    "- Data yang tidak ada di scrapetable_wisata.xlsx langsung di drop saja di byPlaceData.csv (mengurangi storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "DATA = 'data/'\n",
    "\n",
    "dataBaruPath = f'{DATA}scrapetable_wisata.xlsx'\n",
    "dataByPlace = f'{DATA}byPlaceData.csv'\n",
    "dataFiltered = f'{DATA}filtered_byPlaceData.csv'\n",
    "dataNewFix = f'{DATA}new_fixedData.xlsx'\n",
    "\n",
    "dfNew = pd.read_excel(dataBaruPath)\n",
    "dfByPlace = pd.read_csv(dataByPlace)\n",
    "dfFiltered = pd.read_csv(dataFiltered)\n",
    "dfNewFix = pd.read_excel(dataNewFix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfByPlace.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cek Info DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ByPlace\n",
    "print('By Place')\n",
    "print(dfByPlace.info())\n",
    "\n",
    "print()\n",
    "\n",
    "# new\n",
    "print('New')\n",
    "print(dfNew.info())\n",
    "\n",
    "print()\n",
    "\n",
    "# newfixed\n",
    "print('New Fixed')\n",
    "print(dfNewFix.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cek Nilai Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ByPlace\n",
    "print('By Place')\n",
    "print(dfByPlace.isna().sum())\n",
    "\n",
    "print()\n",
    "\n",
    "# new\n",
    "print('New')\n",
    "print(dfNew.isna().sum())\n",
    "\n",
    "print()\n",
    "\n",
    "# newfixed\n",
    "print('New Fixed')\n",
    "print(dfNewFix.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cek Nilai Duplikat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ByPlace\n",
    "print('By Place')\n",
    "print(dfByPlace.duplicated().sum())\n",
    "\n",
    "print()\n",
    "\n",
    "# new\n",
    "print('New')\n",
    "print(dfNew.duplicated().sum())\n",
    "\n",
    "print()\n",
    "\n",
    "# newfixed\n",
    "print('New Fixed')\n",
    "print(dfNewFix.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pemilihan Kolom Data Bu Melany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfNew.latitude.sample(1))\n",
    "print(dfNew.longitude.sample(1))\n",
    "\n",
    "print(dfByPlace.coordinates.sample(1))\n",
    "print(dfByPlace.address.sample(1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfNew.timezone.unique())\n",
    "print(dfNew.review_count.sample(1))\n",
    "print(dfNew.place_id.sample(1))\n",
    "print(dfNew.city.unique())\n",
    "print(dfNew['validasi di jogja dan tetangga'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1: Menghapus kolom dengan banyak missing values\n",
    "dfByPlace_cleaned = dfByPlace.drop(columns=['is_rating_updated', 'is_reviews_updated'])\n",
    "\n",
    "# Dataset 2: Menghapus kolom dengan banyak missing values dan mengisi missing values lainnya\n",
    "dfNew_cleaned = dfNew.drop(columns=['price_level'])\n",
    "\n",
    "# Mengisi missing values pada kolom numerik dengan median\n",
    "dfNew_cleaned['phone_number'].fillna('Unknown', inplace=True)\n",
    "# dfNew_cleaned['review_count'].fillna(dfNew_cleaned['review_count'].median(), inplace=True) (Dipertimbangkan)\n",
    "dfNew_cleaned['rating'].fillna(dfNew_cleaned['rating'].median(), inplace=True)\n",
    "\n",
    "# Mengisi missing values pada kolom string dengan 'Unknown'\n",
    "dfNew_cleaned['website'].fillna('Unknown', inplace=True)\n",
    "columns_to_fill = ['Friday', 'Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'state']\n",
    "for column in columns_to_fill:\n",
    "    dfNew_cleaned[column].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Memeriksa kembali missing values setelah pembersihan\n",
    "missing_values_dfByPlace_cleaned = dfByPlace_cleaned.isnull().sum()\n",
    "missing_values_dfNew_cleaned = dfNew_cleaned.isnull().sum()\n",
    "\n",
    "missing_values_dfByPlace_cleaned, missing_values_dfNew_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menggabungkan Data dan Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggabungkan data dari kedua dataset berdasarkan kolom address\n",
    "# Menentukan keyword untuk filtering\n",
    "keywords = [\"Jawa Tengah\", \"Central Java\", \"Yogyakarta\", \"Special Region of Yogyakarta\"]\n",
    "\n",
    "# Filter Dataset 1\n",
    "filtered_dfByPlace = dfByPlace_cleaned[dfByPlace_cleaned['address'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "\n",
    "# Filter Dataset 2\n",
    "filtered_dfNew = dfNew_cleaned[dfNew_cleaned['full_address'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "\n",
    "# Menggabungkan kedua dataset yang telah difilter\n",
    "combined_dataset = pd.concat([filtered_dfByPlace, filtered_dfNew], ignore_index=True)\n",
    "\n",
    "# Menampilkan jumlah baris dan kolom dari dataset yang digabungkan\n",
    "combined_shape = combined_dataset.shape\n",
    "combined_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the names in both datasets to lowercase for better matching\n",
    "# dfByPlace['name'] = dfByPlace['name'].str.lower()\n",
    "# dfNew['name'] = dfNew['name']\n",
    "\n",
    "# Filter out rows in byPlaceData that do not have a matching name in scrapetable_wisata\n",
    "filtered_data = dfByPlace[(dfByPlace['name'].str.lower()).isin((dfNew['name']).str.lower())]\n",
    "\n",
    "# Now filter based on the address containing 'Jawa Tengah', 'Central Java', or 'Yogyakarta'\n",
    "filtered_data = filtered_data[\n",
    "    filtered_data['address'].str.contains('Jawa Tengah|Central Java|Yogyakarta', case=False)\n",
    "]\n",
    "\n",
    "# Display the first few rows of the filtered data to verify\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered data to a new CSV file\n",
    "filtered_data_path = 'data/filtered_byPlaceData.csv'\n",
    "filtered_data.to_csv(filtered_data_path, index=False)\n",
    "\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambil Data dari DF Baru\n",
    "Pengambilan data yang mungkin masih merupakan wisata dari data baru, tapi tidak ada di data utama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickedData = dfNew[~dfNew['name'].str.lower().isin(filtered_data['name'].str.lower())]\n",
    "\n",
    "filteredCols = filtered_data.columns\n",
    "unpickedCols = unpickedData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data Fix\n",
    "\n",
    "Data yang disini sudah hasil pengambilan dari data baru, yang tidak ada di data lama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf = pd.read_csv('data/fixed_data.csv')\n",
    "fixedDf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cek Nilai Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memindahkan Nilai dari Kolom ke Kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi drop kolom\n",
    "def dropCol(df, lsCol):\n",
    "    col1 = lsCol[0]\n",
    "    col2 = lsCol[1]\n",
    "    \n",
    "    if col1 == 'latitude' and col2 == 'longitude':\n",
    "        df.drop(columns=[col1, col2], inplace=True)\n",
    "    else:\n",
    "        df.drop(columns=[col2], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Fungsi Pemindah Nilai\n",
    "def moveValues(col1, col2, df):\n",
    "    # Kondisi coordinates\n",
    "    if col1 == 'latitude' and col2 == 'longitude':\n",
    "        # Menggabungkan koordinat dan menyimpannya pada kolom 'coordinates'\n",
    "        df['coordinates'] = df.apply(lambda row: f\"{row[col1]},{row[col2]}\" if pd.isna(row['coordinates']) else row['coordinates'], axis=1)\n",
    "        \n",
    "        # Menghapus kolom latitude dan longitude\n",
    "        df = dropCol(df, [col1, col2])\n",
    "    else:\n",
    "        # Mengecek baris dengan NaN pada col1\n",
    "        mask_nullCol1 = df[col1].isna()\n",
    "        \n",
    "        if mask_nullCol1.any():\n",
    "            df.loc[mask_nullCol1, col1] = df.loc[mask_nullCol1, col2]\n",
    "        else:\n",
    "            print('Data tidak ada isinya')\n",
    "        \n",
    "        # Menghapus kolom col1 dan col2\n",
    "        df = dropCol(df, [col1, col2])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kolom Address dan Full Address\n",
    "fixedDf = moveValues('address', 'full_address', fixedDf)\n",
    "# Kolom latitude dan longitude\n",
    "fixedDf = moveValues('latitude', 'longitude', fixedDf)\n",
    "# Kolom latitude dan longitude\n",
    "fixedDf = moveValues('reviews', 'review_count', fixedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hapus Kolom Sisa yang Tidak Digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delCols = ['is_rating_updated', 'is_reviews_updated', 'website', \n",
    "           'business_id', 'phone_number', 'Unnamed: 0.1', 'Unnamed: 0', 'price_level']\n",
    "\n",
    "fixedDf.drop(columns=delCols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menangani Nilai Null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. timezone (Faishal)\n",
    "   \n",
    "Diisi dengan nilai unique, yaitu Asia/Jakarta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf['timezone'] = fixedDf.timezone.fillna('Asia/Jakarta', axis=0)\n",
    "print('Nilai unique: ', fixedDf.timezone.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. types (Akhdan)\n",
    "\n",
    "Diisi sesuai dengan bidangnya, dilihat dari nilai unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nilai unique: ', fixedDf.types.unique())\n",
    "# fixedDf.timezone.fillna('Asia/Jakarta', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. city (Faishal)\n",
    "   \n",
    "Diisi dengan menggunakan regex dari full address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengambil dua bagian terakhir setelah dipisahkan oleh koma\n",
    "def extractCity(df):\n",
    "    for i, row in df.iterrows():\n",
    "        address = row['address']\n",
    "        \n",
    "        # Periksa apakah kolom 'city' kosong (NaN)\n",
    "        if pd.isna(row['city']):\n",
    "            parts = address.split(',')\n",
    "            # Menggabungkan tiga bagian terakhir\n",
    "            df.at[i, 'city'] = ','.join(parts[-2:]).strip()\n",
    "    return df\n",
    "\n",
    "fixedDf = extractCity(fixedDf)\n",
    "\n",
    "# Karena removeNumber bekerja dengan Pandas Series, kita perlu menerapkannya pada keseluruhan kolom\n",
    "fixedDf['city'] = fixedDf['city'].apply(lambda x: pd.Series([x]).str.replace(r'\\d+', '', regex=True).item().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. workday_timing dan closed_on (Faishal)\n",
    "\n",
    "Ambil dari yang hari-hari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workday Timing\n",
    "def fillWorkdayTime(df, lsDays):\n",
    "    for i, row in df.iterrows():\n",
    "        tempTime = []\n",
    "        \n",
    "        for col in lsDays:\n",
    "            if not pd.isna(row[col]):\n",
    "                tempTime.append(row[col])\n",
    "                \n",
    "        if len(tempTime) > 0:\n",
    "            # Menghitung frekuensi kemunculan dan mengambil yang paling sering\n",
    "            most_common_time = Counter(tempTime).most_common(1)[0][0]\n",
    "            df.at[i, 'workday_timing'] = most_common_time\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Closed On\n",
    "# Fungsi untuk mengisi hari-hari yang \"Closed On\"\n",
    "def fillClosedOn(df, lsDays, day_translation):\n",
    "    # Urutan hari dari Senin sampai Minggu\n",
    "    order_days = ['Senin', 'Selasa', 'Rabu', 'Kamis', 'Jumat', 'Sabtu', 'Minggu']\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        tempWord = row['closed_on']  # Mulai dengan nilai existing di kolom 'closed_on'\n",
    "        \n",
    "        # Jika closed_on sudah ada isinya, lewati baris ini\n",
    "        if tempWord and not pd.isna(tempWord):\n",
    "            continue\n",
    "        \n",
    "        closed_days = []  # List untuk menyimpan hari-hari yang tutup berdasarkan lsDays\n",
    "        all_nan = True    # Flag untuk mengecek apakah semua kolom lsDays adalah NaN\n",
    "        \n",
    "        # Iterasi melalui hari-hari dalam lsDays\n",
    "        for col in lsDays:\n",
    "            if pd.isna(row[col]):\n",
    "                closed_days.append(day_translation[col])  # Catat hari yang tutup\n",
    "            else:\n",
    "                all_nan = False  # Jika ada yang bukan NaN, berarti tidak semua hari tutup\n",
    "\n",
    "        # Jika semua kolom hari adalah NaN, isi 'Open All Days'\n",
    "        if all_nan:\n",
    "            tempWord = 'Open All Days'\n",
    "        else:\n",
    "            if closed_days:  # Jika ada hari yang tutup\n",
    "                tempWord = ', '.join(closed_days)\n",
    "                # Menghilangkan hari yang berulang dan mengurutkan\n",
    "                unique_days = sorted(set(tempWord.split(', ')), key=order_days.index)\n",
    "                tempWord = ', '.join(unique_days)\n",
    "        \n",
    "        # Simpan hasil akhir\n",
    "        df.at[i, 'closed_on'] = tempWord\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Days\n",
    "lsDays = ['Sunday', 'Monday', 'Tuesday', 'Wednesday',\n",
    "          'Thursday', 'Friday', 'Saturday']\n",
    "# Dictionary untuk menerjemahkan hari dari bahasa Inggris ke bahasa Indonesia\n",
    "dayTranslation = {\n",
    "    'Sunday': 'Minggu',\n",
    "    'Monday': 'Senin',\n",
    "    'Tuesday': 'Selasa',\n",
    "    'Wednesday': 'Rabu',\n",
    "    'Thursday': 'Kamis',\n",
    "    'Friday': 'Jumat',\n",
    "    'Saturday': 'Sabtu'\n",
    "}\n",
    "\n",
    "# Panggil fungsi fillWorkdayTime\n",
    "fixedDf = fillWorkdayTime(fixedDf, lsDays=lsDays)\n",
    "# Panggil fungsi fillClosedOn\n",
    "fixedDf = fillClosedOn(fixedDf, lsDays, dayTranslation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Kolom-kolom Hari\n",
    "fixedDf = fixedDf.drop(lsDays, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. reviews dan rating (Akhdan)\n",
    "   \n",
    "Manual aja ambil dari maps, kalau memungkinkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil data dari isian manual\n",
    "manualDf = pd.read_excel(f'{DATA}new_fixedData.xlsx')\n",
    "\n",
    "# Merge the datasets on the 'name' column\n",
    "merged_df = pd.merge(fixedDf, manualDf[['name', 'reviews', 'rating']], on='name', how='left', suffixes=('', '_manual'))\n",
    "\n",
    "# Update null values in 'reviews' and 'rating' columns in fixeddf with values from manualdf\n",
    "merged_df['reviews'] = merged_df['reviews'].combine_first(merged_df['reviews_manual'])\n",
    "merged_df['rating'] = merged_df['rating'].combine_first(merged_df['rating_manual'])\n",
    "\n",
    "# Drop the manual columns used for the update\n",
    "fixedDf = merged_df.drop(columns=['reviews_manual', 'rating_manual'])\n",
    "\n",
    "# fill null with '0'\n",
    "fixedDf.reviews.fillna(0, inplace=True)\n",
    "fixedDf.rating.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. reviewer_name, rating_review, dan review_text (Akhdan)\n",
    "\n",
    "ambil dari maps juga, masing2 data 1 ajaa kalo yang null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfDataReviewer(df1, df2):\n",
    "    cols = ['reviewer_name', 'rating_review', 'review_text']\n",
    "    \n",
    "    # Melakukan merge untuk mendapatkan nilai dari df2 ke df1 berdasarkan kolom 'name'\n",
    "    merged_df = df1.merge(df2, left_on='name', right_on='name', suffixes=('', '_manual'))\n",
    "    \n",
    "    # Mengisi nilai null di df1 dengan nilai dari df2\n",
    "    for col in cols:\n",
    "        df1[col] = merged_df[col].combine_first(merged_df[col + '_manual'])\n",
    "    \n",
    "    # Menghapus kolom-kolom dengan suffix '_manual'\n",
    "    cols_to_drop = [col + '_manual' for col in cols]\n",
    "    df1 = df1.drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    return df1\n",
    "\n",
    "fixedDf = tfDataReviewer(fixedDf, manualDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. most_popular_times & popular_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf['most_popular_times'] = fixedDf['most_popular_times'].fillna('Not Present', axis=0)\n",
    "fixedDf['popular_times'] = fixedDf['popular_times'].fillna('Not Present', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. validasi di jogja dan tetangga (Faishal)\n",
    "\n",
    "Langsung isi pake nilai terbanyak aja, keknya udah di jogja dan sekitarnya semua ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf['validasi di jogja dan tetangga'] = fixedDf['validasi di jogja dan tetangga'].fillna('YA', axis=0)\n",
    "fixedDf['validasi di jogja dan tetangga'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghapus Kolom yang Tidak Diperlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf = fixedDf.drop(['timezone', 'place_id', 'place_link',\n",
    "                        'verified', 'state', \n",
    "                        'validasi di jogja dan tetangga',\n",
    "                        'published_at_date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Ke Bahasa Indonesia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ganti bahasa indonesia\n",
    "translationDict = {\n",
    "    'Bantul Regency, Special Region of Yogyakarta': 'Kabupaten Bantul, Daerah Istimewa Yogyakarta',\n",
    "    'Bantul Regency, Special Region of Yogyakarta, Indonesia': 'Kabupaten Bantul, Daerah Istimewa Yogyakarta',\n",
    "    'Yogyakarta City, Special Region of Yogyakarta': 'Kota Yogyakarta, Daerah Istimewa Yogyakarta',\n",
    "    'Sleman Regency, Special Region of Yogyakarta': 'Kabupaten Sleman, Daerah Istimewa Yogyakarta',\n",
    "    'Magelang Regency, Central Java': 'Kabupaten Magelang, Jawa Tengah',\n",
    "    'Magelang Regency, Central Java, Indonesia': 'Kabupaten Magelang, Jawa Tengah',\n",
    "    'Kulon Progo Regency, Special Region of Yogyakarta, Indonesia': 'Kabupaten Kulon Progo, Daerah Istimewa Yogyakarta',\n",
    "    'yogyakarta, Special Region of Yogyakarta, Indonesia': 'Kota Yogyakarta, Daerah Istimewa Yogyakarta',\n",
    "    'Yogyakarta City, Special Region of Yogyakarta, Indonesia': 'Kota Yogyakarta, Daerah Istimewa Yogyakarta',\n",
    "    'Klaten Regency, Central Java, Indonesia': 'Kabupaten Klaten, Jawa Tengah',\n",
    "    'Sleman Regency, Special Region of Yogyakarta': 'Kabupaten Sleman, Daerah Istimewa Yogyakarta',\n",
    "    'Sleman Regency, Special Region of Yogyakarta, Indonesia': 'Kabupaten Sleman, Daerah Istimewa Yogyakarta',\n",
    "    'Bantul Regency, Jawa Tengah, Indonesia': 'Kabupaten Bantul, Daerah Istimewa Yogyakarta',\n",
    "    'Gunung Kidul Regency, Special Region of Yogyakarta, Indonesia': 'Kabupaten Gunung Kidul, Daerah istimewa Yogyakarta',\n",
    "    'Purworejo Regency, Central Java, Indonesia': 'Kabupaten Purworejo, Jawa Tengah'\n",
    "}\n",
    "\n",
    "# Fungsi untuk melakukan translasi berdasarkan dictionary\n",
    "def translate_city(city):\n",
    "    return translationDict.get(city, city)\n",
    "\n",
    "# Apply fungsi translasi ke kolom city\n",
    "fixedDf['city'] = fixedDf['city'].apply(translate_city)\n",
    "fixedDf.city.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### workday_timing & closed_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most_popular_times & popular_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengganti \"Time Label\" dan \"Average Popularity\" ke bahasa Indonesia\n",
    "def translateToIndo(text):\n",
    "    translations = {\n",
    "        'Time Label': 'Label Waktu',\n",
    "        'Average Popularity': 'Rata-rata Popularitas',\n",
    "        'Not Present': 'Tidak Tersedia',\n",
    "        'Sunday': 'Minggu',\n",
    "        'Monday': 'Senin',\n",
    "        'Tuesday': 'Selasa',\n",
    "        'Wednesday': 'Rabu',\n",
    "        'Thursday': 'Kamis',\n",
    "        'Friday': 'Jumat',\n",
    "        'Saturday': 'Sabtu',\n",
    "        'Idle': 'Diam'\n",
    "    }\n",
    "    \n",
    "    # Pastikan text adalah string sebelum memulai penggantian\n",
    "    if isinstance(text, str):\n",
    "        for eng, indo in translations.items():\n",
    "            text = text.replace(eng, indo)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Terapkan fungsi ke kolom most_popular_times\n",
    "fixedDf['most_popular_times'] = fixedDf['most_popular_times'].apply(translateToIndo)\n",
    "fixedDf['popular_times'] = fixedDf['popular_times'].apply(translateToIndo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedDf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengatur gaya visualisasi\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1. Memeriksa missing values\n",
    "missing_values_dfByPlace = dfByPlace.isnull().sum()\n",
    "missing_values_dfNew = dfNew.isnull().sum()\n",
    "missing_values_dfNewFix = dfNewFix.isnull().sum()\n",
    "\n",
    "# 2. Visualisasi distribusi rating\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Dataset 1\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(dfByPlace['rating'], bins=20, kde=True)\n",
    "plt.title('Distribusi Rating - Dataset 1')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frekuensi')\n",
    "\n",
    "# Dataset 2\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(dfNew['rating'], bins=20, kde=True)\n",
    "plt.title('Distribusi Rating - Dataset 2')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frekuensi')\n",
    "\n",
    "# Dataset 3\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(dfNewFix['rating'], bins=20, kde=True)\n",
    "plt.title('Distribusi Rating - Dataset 2')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frekuensi')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Visualisasi distribusi jumlah review\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Dataset 1\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(dfByPlace['reviews'], bins=20, kde=True)\n",
    "plt.title('Distribusi Jumlah Review - Dataset 1')\n",
    "plt.xlabel('Jumlah Review')\n",
    "plt.ylabel('Frekuensi')\n",
    "\n",
    "# Dataset 2\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(dfNew['review_count'], bins=20, kde=True)\n",
    "plt.title('Distribusi Jumlah Review - Dataset 2')\n",
    "plt.xlabel('Jumlah Review')\n",
    "plt.ylabel('Frekuensi')\n",
    "\n",
    "# Dataset 3\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(dfNewFix['review_count'], bins=20, kde=True)\n",
    "plt.title('Distribusi Jumlah Review - Dataset 2')\n",
    "plt.xlabel('Jumlah Review')\n",
    "plt.ylabel('Frekuensi')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "missing_values_dfByPlace, missing_values_dfNew, missing_values_dfNewFix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
