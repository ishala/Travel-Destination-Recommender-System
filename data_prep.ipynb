{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataLamaPath = 'data/new-fix-data.csv'\n",
    "dataBaruPath = 'data/tempat-wisata-di-yogyakarta-overview.csv'\n",
    "dataByPlace = 'data/byPlaceData.csv'\n",
    "# dataNormalizedByPlace = 'data/normalized_byPlaceData.csv'\n",
    "\n",
    "dfOld = pd.read_csv(dataLamaPath)\n",
    "dfNew = pd.read_csv(dataBaruPath)\n",
    "\n",
    "dfByPlace = pd.read_csv(dataByPlace)\n",
    "# dfNormalized = pd.read_csv(dataNormalizedByPlace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOld.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfByPlace.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Assessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Lama\n",
    "dfOld.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Baru\n",
    "dfNew.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfByPlace.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOld.reviews.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOld.name.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data yang diambil: \n",
    "- name\n",
    "- address\n",
    "- coordinates\n",
    "- workday_timing\n",
    "- closed_on\n",
    "- reviews\n",
    "- rating\n",
    "- most_popular_times\n",
    "- popular_times\n",
    "- reviewer_name\n",
    "- rating_review\n",
    "- review_text\n",
    "- published_at_date\n",
    "- accessibility_enabled\n",
    "- planning_enabled\n",
    "- children_enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cek Informasi Kolom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merampingkan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grpByReviewer = dfOld.groupby('name').agg({\n",
    "#     'address': lambda x: list(x),\n",
    "#     'coordinates': lambda x: list(x),\n",
    "#     'workday_timing': lambda x: list(x),\n",
    "#     'closed_on': lambda x: list(x),\n",
    "#     'reviews': lambda x: list(x),\n",
    "#     'rating': lambda x: list(x),\n",
    "#     'most_popular_times': lambda x: list(x),\n",
    "#     'popular_times': lambda x: list(x),\n",
    "#     'popular_times': lambda x: list(x),\n",
    "#     'reviewer_name': lambda x: list(x),\n",
    "#     'rating_review': lambda x: list(x),\n",
    "#     'review_text': lambda x: list(x),\n",
    "#     'published_at_date': lambda x: list(x),\n",
    "#     'accessibility_enabled': lambda x: list(x),\n",
    "#     'planning_enabled': lambda x: list(x),\n",
    "#     'children_enabled': lambda x: list(x)\n",
    "# }).reset_index()\n",
    "\n",
    "# grpByReviewer.to_csv('data/byPlaceData.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisasi Bentuk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percobaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percobaan 1\n",
    "columns_to_normalize = ['address', 'coordinates', 'workday_timing', 'closed_on',\n",
    "       'reviews', 'most_popular_times', 'popular_times', \n",
    "       'accessibility_enabled', 'planning_enabled', 'children_enabled']\n",
    "\n",
    "dfByPlace_normalized = dfByPlace.groupby('name').agg(\n",
    "    {col: lambda x:', '.join(x.dropna().unique()) for col in columns_to_normalize}\n",
    ").reset_index()\n",
    "\n",
    "dfByPlace = dfByPlace.drop(columns=columns_to_normalize).drop_duplicates(subset=['name'])\n",
    "dfByPlace_updated = dfByPlace.merge(dfByPlace_normalized, on='name', how='left')\n",
    "\n",
    "dfByPlace_updated.to_csv(dataByPlace, index=False)\n",
    "\n",
    "dataByPlace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percobaan 2\n",
    "columns_to_normalize = ['address', 'coordinates', 'workday_timing', 'closed_on',\n",
    "                        'reviews', 'most_popular_times', 'popular_times', \n",
    "                        'accessibility_enabled', 'planning_enabled', 'children_enabled']\n",
    "\n",
    "# Normalisasi setiap kolom dengan menggabungkan nilai-nilai duplikat yang ada\n",
    "for col in columns_to_normalize:\n",
    "    dfByPlace[col] = dfByPlace.groupby('name')[col].transform(lambda x: ', '.join(x.dropna().unique()))\n",
    "\n",
    "# Menyimpan hasil ke file yang sama tanpa menghapus kolom atau baris\n",
    "dfByPlace.to_csv('path_to_your_csv_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percobaan 3\n",
    "\n",
    "# Kolom-kolom yang berbentuk list dan perlu dipisahkan ke dalam baris yang terpisah\n",
    "list_columns = [\n",
    "    'coordinates', 'workday_timing', 'closed_on', 'reviews',\n",
    "    'most_popular_times', 'popular_times', 'accessibility_enabled',\n",
    "    'planning_enabled', 'children_enabled'\n",
    "]\n",
    "\n",
    "# Fungsi untuk memisahkan elemen list ke dalam baris yang terpisah\n",
    "def explode_column(dfByPlace, column):\n",
    "    dfByPlace[column] = dfByPlace[column].apply(lambda x: x.split(',') if isinstance(x, str) else [])\n",
    "    dfByPlace = dfByPlace.explode(column).reset_index(drop=True)\n",
    "    return dfByPlace\n",
    "\n",
    "# Memisahkan setiap kolom yang berisi list\n",
    "for column in list_columns:\n",
    "    dfByPlace = explode_column(dfByPlace, column)\n",
    "\n",
    "# Menghapus duplikasi\n",
    "dfByPlace = dfByPlace.drop_duplicates()\n",
    "\n",
    "# Melakukan normalisasi data (gabung kembali jika diperlukan)\n",
    "# Misalnya normalisasi pada kolom 'reviews'\n",
    "dfByPlace['coordinates'] = dfByPlace.groupby(['unique_key'])['coordinates'].transform(lambda x: ','.join(x))\n",
    "dfByPlace['working_timing'] = dfByPlace.groupby(['unique_key'])['working_timing'].transform(lambda x: ','.join(x))\n",
    "dfByPlace['closed_on'] = dfByPlace.groupby(['unique_key'])['closed_on'].transform(lambda x: ','.join(x))\n",
    "dfByPlace['reviews'] = dfByPlace.groupby(['unique_key'])['reviews'].transform(lambda x: ','.join(x))\n",
    "dfByPlace['most_popular_times'] = dfByPlace.groupby(['unique_key'])['most_popular_times'].transform(lambda x: ','.join(x))\n",
    "dfByPlace['popular_times'] = dfByPlace.groupby(['unique_key'])['popular_times'].transform(lambda x: ','.join(x))\n",
    "dfByPlace['accessibility_enabled'] = dfByPlace.groupby(['unique_key'])['accessibility_enabled'].transform(lambda x: ','.join(x))\n",
    "dfByPlace['planning_enabled'] = dfByPlace.groupby(['unique_key'])['planning_enabled'].transform(lambda x: ','.join(x))\n",
    "dfByPlace['children_enabled'] = dfByPlace.groupby(['unique_key'])['children_enabled'].transform(lambda x: ','.join(x))\n",
    "\n",
    "# Menyimpan kembali dataset yang telah dinormalisasi\n",
    "output_file_path = 'data/normalized_byPlaceData.csv'\n",
    "dfByPlace.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data yang telah dinormalisasi telah disimpan di {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percobaan 4\n",
    "\n",
    "chunksize = 10000  # Ukuran chunks (dapat disesuaikan)\n",
    "\n",
    "# Kolom yang berbentuk list dan perlu dipisahkan ke dalam baris yang terpisah\n",
    "list_columns = [\n",
    "    'coordinates', 'workday_timing', 'closed_on', 'reviews',\n",
    "    'most_popular_times', 'popular_times', 'accessibility_enabled',\n",
    "    'planning_enabled', 'children_enabled'\n",
    "]\n",
    "\n",
    "# Membuat file output kosong\n",
    "output_file_path = 'data/normalized_byPlaceData.csv'\n",
    "header_written = False\n",
    "\n",
    "# Proses per chunk\n",
    "for chunk in pd.read_csv('data/byPlaceData.csv', chunksize=chunksize):\n",
    "    for column in list_columns:\n",
    "        # Memisahkan kolom yang berisi list\n",
    "        chunk[column] = chunk[column].apply(lambda x: x.split(',') if isinstance(x, str) else [])\n",
    "        chunk = chunk.explode(column).reset_index(drop=True)\n",
    "    \n",
    "    # Menghapus duplikasi\n",
    "    chunk = chunk.drop_duplicates()\n",
    "\n",
    "    # Simpan chunk yang telah diproses ke file CSV\n",
    "    if not header_written:\n",
    "        chunk.to_csv(output_file_path, mode='w', index=False, header=True)\n",
    "        header_written = True\n",
    "    else:\n",
    "        chunk.to_csv(output_file_path, mode='a', index=False, header=False)\n",
    "\n",
    "print(f\"Data yang telah dinormalisasi telah disimpan di {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambil Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "\n",
    "def update_rating(data1, data2, iterator):\n",
    "    # Loop melalui setiap baris di data1\n",
    "    for idx, row in data2.iterrows():\n",
    "        # Cari baris di data2 dengan nama_wisata yang sama\n",
    "        matching_row = data1[data1['name'] == row['name']]\n",
    "        \n",
    "        if not matching_row.empty:\n",
    "            print('Ada data', row['name'])\n",
    "            # Jika ada kecocokan, perbarui jumlah_reviews di data1\n",
    "            data1.at[idx, 'rating'] = matching_row['rating'].values[0]\n",
    "            data1.at[idx, 'is_rating_updated'] = 1\n",
    "            iterator = iterator + 1\n",
    "        else:\n",
    "            print('Tidak ada data', row['name'])\n",
    "            data1.at[idx, 'is_rating_updated'] = 0\n",
    "    \n",
    "    # Kembalikan data1 yang sudah diperbarui\n",
    "    return data1, iterator\n",
    "\n",
    "updatedDf, iterator = update_rating(dfByPlace, dfNew, iterator)\n",
    "print(iterator)\n",
    "updatedDf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jumlah Reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOld[dfOld['name'] == 'Taman Pintar Yogyakarta'].reviews.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "\n",
    "def update_reviews(data1, data2, iterator):\n",
    "    # Loop melalui setiap baris di data1\n",
    "    for idx, row in data2.iterrows():\n",
    "        # Cari baris di data2 dengan nama_wisata yang sama\n",
    "        matching_row = data1[data1['name'] == row['name']]\n",
    "        \n",
    "        if not matching_row.empty:\n",
    "            print('Ada data', row['name'])\n",
    "            # Jika ada kecocokan, perbarui jumlah_reviews di data1\n",
    "            data1.at[idx, 'reviews'] = matching_row['reviews'].values[0]\n",
    "            data1.at[idx, 'is_reviews_updated'] = 1\n",
    "            iterator = iterator + 1\n",
    "        else:\n",
    "            print('Tidak ada data', row['name'])\n",
    "            data1.at[idx, 'is_reviews_updated'] = 0\n",
    "    \n",
    "    # Kembalikan data1 yang sudah diperbarui\n",
    "    return data1, iterator\n",
    "\n",
    "updatedDf, iterator = update_reviews(dfByPlace, dfNew, iterator)\n",
    "print(iterator)\n",
    "updatedDf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOld[dfOld['name'] == 'Taman Pintar Yogyakarta'].reviews.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
